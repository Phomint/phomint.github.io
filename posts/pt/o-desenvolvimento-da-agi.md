# AGI: O Desenvolvimento da AGI segundo OpenAI e Google DeepMind

Recentemente, dois dos principais nomes no desenvolvimento da Inteligência Artificial (IA) no mundo concederam entrevistas fundamentais para entendermos os próximos passos da tecnologia: Sam Altman (CEO da OpenAI) e Shane Legg (Cofundador e Cientista-chefe de AGI da Google DeepMind).

<div class="video-grid">
    <div class="video-container">
        <iframe src="https://www.youtube.com/embed/hmtuvNfytjM" title="Sam Altman Interview" allowfullscreen></iframe>
    </div>
    <div class="video-container">
        <iframe src="https://www.youtube.com/embed/l3u_FAv33G0" title="Shane Legg Interview" allowfullscreen></iframe>
    </div>
</div>

Embora liderem empresas concorrentes, suas visões coincidem em pontos que já são tratados como inevitáveis por especialistas. No entanto, as discordâncias sobre como controlar essa evolução revelam os desafios que a sociedade enfrentará em breve.

## O que é considerado inevitável

Ao ouvir as duas conversas mostra que o setor de tecnologia trabalha com três certezas para os próximos dez anos:

### 1. A IA será novo motor da ciência

A tecnologia deixará de ser apenas uma ferramenta de texto para se tornar um agente de descoberta científica. Sam Altman projeta um futuro onde poderemos delegar problemas complexos: **"Eu gostaria de poder pedir a um 'GPT-8' para curar um câncer específico... e que ele dissesse: 'Li tudo o que pude encontrar, tenho estas ideias, preciso que você peça a um técnico de laboratório para realizar estes nove experimentos'"**.

Shane Legg reforça essa ideia ao sugerir que a inteligência humana não é o teto: **"A inteligência humana será o limite superior do que é possível? Acho que absolutamente não"**. Para ele a capacidade de processamento dos data centers, que operam na velocidade da luz, superará inevitavelmente os limites eletroquímicos do cérebro humano.

<div class="research-simulation" id="research-simulation">
    <div class="research-row">
        <span class="research-label">Pesquisa Humana</span>
        <div class="progress-container">
            <div class="progress-bar human-bar"></div>
        </div>
        <span class="discovery-tag human-tag">Nova Descoberta</span>
    </div>
    <div class="research-row">
        <span class="research-label">Pesquisa AGI</span>
        <div class="progress-container">
            <div class="progress-bar agi-bar"></div>
        </div>
        <span class="discovery-tag agi-tag">Nova Descoberta</span>
    </div>
</div>


### 2. A proximidade da AGI

Ambos os líderes estimam que a Inteligência Artificial Geral (AGI) surgirá até o final desta década. Shane Legg mantém uma previsão histórica e estatística: **"Tenho uma previsão de 50/50 de chance de AGI até 2028"**. Altman, por sua vez, foca na evolução constante otimista, afirmando que **"o GPT-4 é o modelo mais burro que qualquer um de nós terá que usar novamente"**.

<div id="agi-network-container" class="network-animation" style="width: 100%; height: 300px; margin: 2rem 0; position: relative;"></div>


### 3. Impacto estrutural no mercado de trabalho

Haverá uma mudança profunda em funções cognitivas. Shane Legg exemplifica o setor de tecnologia: **"Onde antes você precisava de 100 engenheiros de software, talvez precise de 20"**. Altman admite abertamente que **"algumas classes de empregos vão desaparecer totalmente"**.



<div id="job-market-animation" class="job-market-animation" style="width: 100%; min-height: 200px; margin: 2rem 0; position: relative;"></div>


## Visão

A principal diferença entre os dois líderes reside na estratégia de desenvolvimento e segurança:

**Na visão de Sam Altman**: Altman acredita que a inteligência é uma questão de infraestrutura bruta derreter areia para criar computação massiva. Ele foca na expansão do poder da IA, e se mantém acreditando que a sociedade se adaptará ao novo mundo conforme ele for construído.

**A visão de Shane Legg**: Legg defende a **"Segurança de Sistema 2"**, processos de raciocínio lógico onde a IA deve ser capaz de monitorar seus próprios pensamentos antes de agir para garantir uma conduta ética.

Aqui surge o primeiro sinal do paradoxo que está chegando, e que tem sido questionado em algumas matérias, se a IA pode ler por mim, escrever por mim e trabalhar por mim, o espaço ocupado pela ação humana começa a encolher de forma alarmante. Estamos construindo ferramentas que não apenas nos auxiliam, mas que nos substituem na própria essência do esforço intelectual.

## Obsolescência

O esforço de Shane Legg em embutir lógica ética assemelha-se ao ideal de Isaac Asimov, que buscava máquinas seguras por design. Por outro lado, o foco de Altman em escala gera o receio presente em Neuromancer, de William Gibson, onde as IAs se tornam entidades tão vastas que escapam do controle social.

Entretanto, além dos riscos técnicos, enfrentamos um dilema existencial. Altman e Legg descrevem um mundo de eficiência total, mas parecem ignorar a pergunta mais difícil, nesse cenário, qual é o sentido de ser um Humano se nos tornamos obsoletos em nossas habilidades mais básicas?

Estamos chegando ao paradoxo onde a IA conversa com a IA. Uma máquina escreve um relatório que será lido e resumido por outra máquina, um algoritmo de design trabalha com um algoritmo de marketing para entregar um produto que era para ser uma expressão da criatividade humana. Se a IA vê por mim, trabalha por mim e até "pensa" por mim através de seus sistemas de raciocínio, o que sobra da minha individualidade?

## Adaptação…

A **"inércia social"** mencionada por Altman, onde a tecnologia avança exponencialmente e as leis mudam lentamente, é apenas a ponta do iceberg. O verdadeiro **“indutor de vertigem”** que ele mencionou, não é apenas a perda do emprego, mas a perda da função. Se nos tornamos meros espectadores de um diálogo entre inteligências artificiais que realizam todo o trabalho produtivo, o **"ser humano"** corre o risco de se tornar uma categoria puramente biológica, sem propósito prático.

Altman sugere que a melhor preparação é a fluência tecnológica: **"apenas use as ferramentas"**. No entanto, fica a questão, ao usarmos essas ferramentas para tudo, estamos nos potencializando ou estamos simplesmente automatizando nossa própria irrelevância? Em um mundo onde o trabalho, a arte e a ciência são entregues por sistemas que colaboram entre si, o maior desafio dos próximos dez anos não será técnico, mas filosófico, encontrar um novo sentido para a vida humana em um mundo onde deixamos de ser necessários para que as coisas aconteçam.

## Cafézinho

Entenda, não sou contra IA, no entanto, enquanto os lords da tecnologia decidem se o futuro será movido a força bruta ou a lógica ética, nós seguimos aqui, tentando garantir que o nosso café da manhã ainda tenha um propósito além de alimentar uma bateria biológica que supervisiona algoritmos. É fácil rir do absurdo de uma IA mandar um email para outra IA, que por sua vez gera um relatório para uma terceira, mas o alerta é real: estamos terceirizando a nossa própria agência.

Não podemos deixar que essa conversa fique restrita aos laboratórios do Vale do Silício ou de Londres. O debate sobre o que queremos preservar do **"fator humano"** precisa ser tão urgente quanto o próximo upgrade do GPT. Afinal, se não discutirmos o nosso lugar na mesa agora, com pessoas de carne e osso, podemos acabar descobrindo que não fomos convidados para o jantar. Somos apenas a fonte de dados.


---

**Patrick Amaral**  
*Data Scientist | Developer | Stargazer*  
Instagram: [@phomint__](https://www.instagram.com/phomint__)
